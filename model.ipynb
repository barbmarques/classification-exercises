{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exercises\n",
    "\n",
    "## <font color = \"blue\">Decision Tree Exercises<font color = \"black\"> \n",
    "\n",
    "**Using the *titanic* data, in your classification-exercises repository, create a notebook, ```model.ipynb``` where you will do the following:**\n",
    "\n",
    "## Decision Tree: Exercise 1\n",
    "\n",
    "**What is your baseline prediction? What is your baseline accuracy?** *remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from env import host, password, user \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import prepare\n",
    "import acquire\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acquiring data\n",
    "titanic_raw = acquire.get_titanic_data()\n",
    "\n",
    "#take a look at data\n",
    "titanic_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    return df.assign(\n",
    "        embark_town=df.embark_town.fillna('Southampton'),\n",
    "        embarked=df.embarked.fillna('O'),\n",
    "    )\n",
    "\n",
    "def remove_columns(df):\n",
    "    return df.drop(columns=['deck'])\n",
    "\n",
    "def encode_embarked(df):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df.embarked)\n",
    "    return df.assign(embarked_encode = encoder.transform(df.embarked))\n",
    "\n",
    "def prep_titanic_data(df):\n",
    "    df = df\\\n",
    "        .pipe(handle_missing_values)\\\n",
    "        .pipe(remove_columns)\\\n",
    "        .pipe(encode_embarked)\n",
    "    return df\n",
    "\n",
    "def train_validate_test_split(df, seed=123):\n",
    "    train_and_validate, test = train_test_split(\n",
    "        df, test_size=0.2, random_state=seed, stratify=df.survived\n",
    "    )\n",
    "    train, validate = train_test_split(\n",
    "        train_and_validate,\n",
    "        test_size=0.3,\n",
    "        random_state=seed,\n",
    "        stratify=train_and_validate.survived,\n",
    "    )\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   passenger_id     891 non-null    int64  \n",
      " 1   survived         891 non-null    int64  \n",
      " 2   pclass           891 non-null    int64  \n",
      " 3   sex              891 non-null    object \n",
      " 4   age              714 non-null    float64\n",
      " 5   sibsp            891 non-null    int64  \n",
      " 6   parch            891 non-null    int64  \n",
      " 7   fare             891 non-null    float64\n",
      " 8   embarked         891 non-null    object \n",
      " 9   class            891 non-null    object \n",
      " 10  embark_town      891 non-null    object \n",
      " 11  alone            891 non-null    int64  \n",
      " 12  embarked_encode  891 non-null    int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic = prep_titanic_data(titanic_raw)\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(columns=['passenger_id','pclass','embarked','embarked_encode', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode variables\n",
    "dummies = pd.get_dummies(titanic[['embark_town', 'sex', 'class']], drop_first=True)\n",
    "titanic = pd.concat([titanic, dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  sibsp  parch     fare  alone  embark_town_Queenstown  \\\n",
       "0         0      1      0   7.2500      0                       0   \n",
       "1         1      1      0  71.2833      0                       0   \n",
       "2         1      0      0   7.9250      1                       0   \n",
       "3         1      1      0  53.1000      0                       0   \n",
       "4         0      0      0   8.0500      1                       0   \n",
       "\n",
       "   embark_town_Southampton  sex_male  class_Second  class_Third  \n",
       "0                        1         1             0            1  \n",
       "1                        0         0             0            0  \n",
       "2                        1         0             0            1  \n",
       "3                        1         0             0            0  \n",
       "4                        1         1             0            1  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the old columns\n",
    "titanic = titanic.drop(columns=['embark_town', 'sex', 'class'])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "train, validate, test = train_validate_test_split(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 10), (214, 10), (179, 10))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be attempting to make a Decision Tree Classifier Model that will predict survival on the \n",
    "# Titanic that performs better than the baseline.\n",
    "\n",
    "#target = survived (1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['baseline_assumption_not_survived'] = 0\n",
    "baseline_accuracy = (train.survived == train.baseline_assumption_not_survived).mean()\n",
    "baseline_accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Exercise 2\n",
    "\n",
    "**Fit the decision tree classifier to your training sample and transform.** (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a blank, new Decision Tree model\n",
    "# Be sure to set the max_depth argument\n",
    "\n",
    "clf1 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X inputs and y target variable for each split\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived # labeled data == supervise algorithm\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's train our model on the training data\n",
    "# fitting == training the model\n",
    "clf = clf1.fit(X_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model so it can explain itself!\n",
    "# dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "# graph = graphviz.Source(dot_data) \n",
    "\n",
    "# graph.render('tips_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Exercise 3\n",
    "\n",
    "**Evaluate your in-sample results using the model score, confusion matrix, and classification report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    330\n",
       "1    168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll make a set of predictions using this trained model\n",
    "y_pred = clf1.predict(X_train)\n",
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9457831325301205"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model score on accuracy:\n",
    "accuracy = clf1.score(X_train,y_train)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[305,   2],\n",
       "       [ 25, 166]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9242424242424242,\n",
       "  'recall': 0.993485342019544,\n",
       "  'f1-score': 0.9576138147566718,\n",
       "  'support': 307},\n",
       " '1': {'precision': 0.9880952380952381,\n",
       "  'recall': 0.8691099476439791,\n",
       "  'f1-score': 0.9247910863509748,\n",
       "  'support': 191},\n",
       " 'accuracy': 0.9457831325301205,\n",
       " 'macro avg': {'precision': 0.9561688311688312,\n",
       "  'recall': 0.9312976448317616,\n",
       "  'f1-score': 0.9412024505538233,\n",
       "  'support': 498},\n",
       " 'weighted avg': {'precision': 0.9487321580695075,\n",
       "  'recall': 0.9457831325301205,\n",
       "  'f1-score': 0.9450251779585028,\n",
       "  'support': 498}}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report = classification_report(y_train, y_pred, output_dict = True)\n",
    "class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.993485</td>\n",
       "      <td>0.957614</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.869110</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.956169</td>\n",
       "      <td>0.931298</td>\n",
       "      <td>0.941202</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.948732</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945025</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.924242  0.993485  0.957614  307.000000\n",
       "1              0.988095  0.869110  0.924791  191.000000\n",
       "accuracy       0.945783  0.945783  0.945783    0.945783\n",
       "macro avg      0.956169  0.931298  0.941202  498.000000\n",
       "weighted avg   0.948732  0.945783  0.945025  498.000000"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(class_report).rename({0: 'death', 1: 'survived'}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Exercise 4\n",
    "\n",
    "**Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[305,   2],\n",
       "       [ 25, 166]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_df = pd.DataFrame(conf, columns=['predict_death','predict_survive'], index = ['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>25</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predict_death  predict_survive\n",
       "actual_death              305                2\n",
       "actual_survive             25              166"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_df = pd.DataFrame([['true negative','false positive'],['false negative', 'true positive']], columns=['predict_death','predict_survive'], index = ['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict_death predict_survive\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to calculate these metrics\n",
    "\n",
    "def get_metrics_binary(cnf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a \n",
    "    binary classifier and prints out metrics based on values in \n",
    "    variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    returns a classification report dataframe (transposed).\n",
    "    '''\n",
    "    accuracy = clf.score(X_train,y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict = True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    True Positive Rate is {tpr:.3}, False Positive Rate is {fpr:.3},\n",
    "    True Negative Rate is {tnr:.3}, False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.9458\n",
      "    True Positive Rate is 0.869, False Positive Rate is 0.00651,\n",
      "    True Negative Rate is 0.993, False Negative Rate is 0.131\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.993485</td>\n",
       "      <td>0.957614</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.869110</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.956169</td>\n",
       "      <td>0.931298</td>\n",
       "      <td>0.941202</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.948732</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945025</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.924242  0.993485  0.957614  307.000000\n",
       "1              0.988095  0.869110  0.924791  191.000000\n",
       "accuracy       0.945783  0.945783  0.945783    0.945783\n",
       "macro avg      0.956169  0.931298  0.941202  498.000000\n",
       "weighted avg   0.948732  0.945783  0.945025  498.000000"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function\n",
    "report_df = get_metrics_binary(clf1)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Exercise 5\n",
    "\n",
    "**Run through steps 2-4 using a different ```max_depth``` value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf2\n",
    "clf2 = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf2.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Exercise 6\n",
    "\n",
    "**Which model performs better on your in-sample data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.9458\n",
      "    True Positive Rate is 0.702, False Positive Rate is 0.101,\n",
      "    True Negative Rate is 0.899, False Negative Rate is 0.298\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "report_df = get_metrics_binary(clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.899023</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.820475</td>\n",
       "      <td>0.800297</td>\n",
       "      <td>0.807654</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.822421</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.820430</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.828829  0.899023  0.862500  307.000000\n",
       "1              0.812121  0.701571  0.752809  191.000000\n",
       "accuracy       0.823293  0.823293  0.823293    0.823293\n",
       "macro avg      0.820475  0.800297  0.807654  498.000000\n",
       "weighted avg   0.822421  0.823293  0.820430  498.000000"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Exercise 7\n",
    "\n",
    "**Which model performs best on your out-of-sample data, the ```validate``` set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for our validation sets\n",
    "y_val_pred_1 = clf1.predict(validate)\n",
    "y_val_pred_2 = clf2.predict(validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation accuracy\n",
    "accuracy_v_1 = clf1.score((validate), validate.survived)\n",
    "accuracy_v_2 = clf2.score((validate), validate.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43457943925233644, 0.6074766355140186)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_v_1, accuracy_v_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf2, feature_names= X_train.columns, rounded = True, filled = True, out_file=None)\n",
    "graph = graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_model_2_tree.pdf'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.render('titanic_model_2_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf2, feature_names= X_train.columns, rounded = True, filled = True, out_file=None)\n",
    "graph = graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_model_1_tree.pdf'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.render('titanic_model_1_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"blue\">Random Forest Exercises<font color = \"black\"> \n",
    "\n",
    "## Random Forest: Exercise 1\n",
    "\n",
    "**Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf=1,max_depth=10,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Exercise 2\n",
    "\n",
    "**Evaluate your results using the model score, confusion matrix, and classification report.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06892937 0.04922884 0.38141952 0.02427634 0.01283513 0.0326652\n",
      " 0.34010557 0.02025616 0.07028387 0.        ]\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Exercise 3\n",
    "\n",
    "**Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "#Score the model for accuracy\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'.format(rf.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302,   5],\n",
       "       [ 23, 168]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_1 = (confusion_matrix(y_train, y_pred))\n",
    "cnf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.9438\n",
      "    True Positive Rate is 0.88, False Positive Rate is 0.0163,\n",
      "    True Negative Rate is 0.984, False Negative Rate is 0.12\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.929231</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.950165</td>\n",
       "      <td>0.931647</td>\n",
       "      <td>0.939387</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.945288</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943186</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.929231  0.983713  0.955696  307.000000\n",
       "1              0.971098  0.879581  0.923077  191.000000\n",
       "accuracy       0.943775  0.943775  0.943775    0.943775\n",
       "macro avg      0.950165  0.931647  0.939387  498.000000\n",
       "weighted avg   0.945288  0.943775  0.943186  498.000000"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_metrics_binary(cnf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a \n",
    "    binary classifier and prints out metrics based on values in \n",
    "    variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    returns a classification report dataframe (transposed).\n",
    "    '''\n",
    "    accuracy = cnf.score(X_train,y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict = True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    True Positive Rate is {tpr:.3}, False Positive Rate is {fpr:.3},\n",
    "    True Negative Rate is {tnr:.3}, False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_metrics_binary(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deceased</th>\n",
       "      <td>0.929231</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.950165</td>\n",
       "      <td>0.931647</td>\n",
       "      <td>0.939387</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.945288</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.943186</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "deceased       0.929231  0.983713  0.955696  307.000000\n",
       "survived       0.971098  0.879581  0.923077  191.000000\n",
       "accuracy       0.943775  0.943775  0.943775    0.943775\n",
       "macro avg      0.950165  0.931647  0.939387  498.000000\n",
       "weighted avg   0.945288  0.943775  0.943186  498.000000"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_train,y_pred, output_dict=True)).rename(columns={'0': 'deceased', '1': 'survived'}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Exercise 4\n",
    "\n",
    "**Run through steps increasing your min_samples_leaf and decreasing your max_depth.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(min_samples_leaf=3, max_depth=3,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, min_samples_leaf=3, random_state=123)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06267687 0.0187328  0.18693544 0.04129274 0.01346748 0.03571904\n",
      " 0.4893116  0.01451785 0.13734617 0.        ]\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "print(rf1.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "#Score the model for accuracy\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'.format(rf1.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_binary(cnf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a \n",
    "    binary classifier and prints out metrics based on values in \n",
    "    variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    returns a classification report dataframe (transposed).\n",
    "    '''\n",
    "    accuracy = cnf.score(X_train,y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict = True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    True Positive Rate is {tpr:.3}, False Positive Rate is {fpr:.3},\n",
    "    True Negative Rate is {tnr:.3}, False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.8193\n",
      "    True Positive Rate is 0.88, False Positive Rate is 0.0163,\n",
      "    True Negative Rate is 0.984, False Negative Rate is 0.12\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "class_report1 = get_metrics_binary(rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1: min samples 1, max depth 10\n",
      "\n",
      "    The accuracy for our model is 0.9438\n",
      "    True Positive Rate is 0.88, False Positive Rate is 0.0163,\n",
      "    True Negative Rate is 0.984, False Negative Rate is 0.12\n",
      "    \n",
      "-------------------------------------------\n",
      " Model #2: min samples 3, max_depth 3\n",
      "\n",
      "\n",
      "    The accuracy for our model is 0.8193\n",
      "    True Positive Rate is 0.88, False Positive Rate is 0.0163,\n",
      "    True Negative Rate is 0.984, False Negative Rate is 0.12\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print('Model #1: min samples 1, max depth 10')\n",
    "class_report_val = get_metrics_binary(rf)\n",
    "print('-------------------------------------------\\n Model #2: min samples 3, max_depth 3\\n')\n",
    "class_report_val1 = get_metrics_binary(rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Exercise 5\n",
    "\n",
    "**What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302,   5],\n",
       "       [ 23, 168]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0               1\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a key for reference\n",
    "rubric_df = pd.DataFrame([['true negative', 'false positive'], ['false negative', 'true positive']], index = ['actual_death','actual_survive'])\n",
    "rubric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After making a few models, which one has the best performance (or closest metrics) on both train and validate?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy:\n",
    "# accuracy = (true positives + true negatives) / (true positives + true negatives + false positives + false negatives)\n",
    "\n",
    "# True Positive Rate: Sensitivity\n",
    "# RECALL for the positive class --> out of those that actually survived, how many did we predict would survive?\n",
    "# TPR = true positives / (true positives + false negatives)\n",
    "#  If we wanted to calculate PRECISION, it would be true positives / (true positives + false postives)\n",
    "# Recall being true positives over the sum of the row, precision being the true positive over the sum of the column\n",
    "# i.e, out of the values we predicted survived, how many were actual survivors?\n",
    "\n",
    "# False Positive Rate: \n",
    "# FPR = false positives / (false positive + true negatives)\n",
    "\n",
    "# True Negative Rate: Specificity\n",
    "# Recall for the negative class --> out of those that perished, how many did we predict would not make it?\n",
    "# TNR = true negatives / (true negatives + false positives)\n",
    "\n",
    "# False negative rate:\n",
    "# FNR = false negatives / (false negatives + true positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>K-Nearest Neighbor<font color = 'black'>\n",
    "\n",
    "**Continue working in your ```model``` file with the *titanic* dataset.**\n",
    "\n",
    "\n",
    "## KNN: Exercise 1\n",
    "\n",
    "**Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Exercise 2\n",
    "\n",
    "**Evaluate your results using the model score, confusion matrix, and classification report.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Exercise 3\n",
    "\n",
    "**Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Exercise 4\n",
    "\n",
    "**Run through steps 2-4 setting k to 10**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Exercise 5\n",
    "\n",
    "**Run through setps 2-4 setting k to 20**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Exercise 6\n",
    "\n",
    "**What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Exercise 7\n",
    "\n",
    "**Which model performs best on our out-of-sample data from ```validate```?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>Logistic Regression Exercises<font color = 'black'>\n",
    "\n",
    "In these exercises, we'll continue working with the *titanic* dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, **choose a threshold that optimizes for accuracy.**\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named ```model``` within your classification-exercises repository. Add, commit, and push your work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Exercise 1\n",
    "\n",
    "**Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR: Exercise 2\n",
    "\n",
    "**Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR: Exercise 3\n",
    "\n",
    "**Try out other combinations of features and models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR: Exercise 4\n",
    "\n",
    "**Use you best 3 models to predict and evaluate on your validate sample.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR: Exercise 5\n",
    "\n",
    "**Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1:\n",
    "\n",
    "**How do different strategies for handling the missing values in the age column affect model performance?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 2:\n",
    "\n",
    "**How do different strategies for encoding sex affect model performance?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "Screen%20Shot%202021-02-28%20at%206.01.18%20PM.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 3: \n",
    "\n",
    "**```scikit-learn```'s ```LogisticRegression``` classifier is actually applying ```a regularization penalty to the coefficients``` by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the ```C``` hyper parameter. Small values of ```C``` correspond to a larger penalty, and large values of ```C``` correspond to a smaller penalty.**\n",
    "\n",
    "**Try out the following values for ```C``` and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.**\n",
    "\n",
    "![Screen%20Shot%202021-02-28%20at%206.01.18%20PM.png](attachment:Screen%20Shot%202021-02-28%20at%206.01.18%20PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Bonus\n",
    "\n",
    " **how does scaling the data interact with your choice of ```C```?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
